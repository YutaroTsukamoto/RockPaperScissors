{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfe5bb1",
   "metadata": {},
   "source": [
    "# データ作成手順（MediaPipe Hands を使って Rock-Paper-Scissors フォルダから 3×21 次元の座標＋ラベルを作る）\n",
    "\n",
    "想定フォルダ構成:\n",
    "- Rock-Paper-Scissors/\n",
    "    - rock/\n",
    "    - paper/\n",
    "    - scissors/\n",
    "    - ...（各サブフォルダに画像が入っている）\n",
    "\n",
    "やることの要点:\n",
    "1. 画像を読み込み、MediaPipe Hands で手検出・ランドマーク取得。\n",
    "2. 21点それぞれの (x, y, z) を取得して配列化。\n",
    "     - 典型は shape=(21, 3)（各ランドマークに対して x,y,z）。\n",
    "     - 要件の「3×21」に合わせる場合は転置して shape=(3, 21) にする。\n",
    "3. クラスラベル（rock/paper/scissors）を数値にマップして保持。\n",
    "4. 全データをまとめて保存（.npz/.npy/.csv 等）。\n",
    "\n",
    "サンプルコード（実行セルに貼って使ってください）:\n",
    "\n",
    "```python\n",
    "# 必要パッケージ: mediapipe, opencv-python, numpy\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "data_X = []  # 各要素は shape=(3,21) や flatten 63-d\n",
    "data_y = []\n",
    "\n",
    "label_map = {'rock':0, 'paper':1, 'scissors':2}\n",
    "root = \"Rock-Paper-Scissors\"\n",
    "\n",
    "with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
    "        for label_name, label_id in label_map.items():\n",
    "                folder = os.path.join(root, label_name)\n",
    "                if not os.path.isdir(folder):\n",
    "                        continue\n",
    "                for fname in os.listdir(folder):\n",
    "                        path = os.path.join(folder, fname)\n",
    "                        img = cv2.imread(path)\n",
    "                        if img is None:\n",
    "                                continue\n",
    "                        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        results = hands.process(img_rgb)\n",
    "                        if results.multi_hand_landmarks:\n",
    "                                lm = results.multi_hand_landmarks[0].landmark  # 21 landmarks\n",
    "                                arr = np.array([[p.x, p.y, p.z] for p in lm])  # shape (21,3)\n",
    "                                arr = arr.T  # -> shape (3,21) to satisfy \"3×21\"\n",
    "                                data_X.append(arr)\n",
    "                                data_y.append(label_id)\n",
    "                        else:\n",
    "                                # ランドマーク検出できない画像はスキップ（必要なら代替処理）\n",
    "                                continue\n",
    "\n",
    "# numpy 配列に変換\n",
    "X = np.stack(data_X)  # shape (N, 3, 21)\n",
    "y = np.array(data_y)  # shape (N,)\n",
    "\n",
    "# 保存例\n",
    "np.savez_compressed(\"rps_hands_3x21.npz\", X=X, y=y)\n",
    "# もしくはフラット化して CSV にする場合:\n",
    "# X_flat = X.reshape(X.shape[0], -1)  # shape (N, 63)\n",
    "# np.savetxt(\"rps_hands_63d.csv\", np.c_[y.reshape(-1,1), X_flat], delimiter=\",\")\n",
    "```\n",
    "\n",
    "注意点:\n",
    "- MediaPipe の x,y は正規化座標（画像幅・高さで 0..1）。絶対ピクセル座標が必要なら x*width, y*height に変換してください。z は相対深度。\n",
    "- 複数手が写っている画像や検出失敗の扱い（スキップ、補完など）を方針に合わせて実装してください。\n",
    "- データ増強や正規化は学習時に行うのが一般的です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c069e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了: Rock-Paper-Scissors-merged に統合しました\n",
      "  rock: 964 枚\n",
      "  paper: 964 枚\n",
      "  scissors: 964 枚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src_root = \"Rock-Paper-Scissors\"\n",
    "dst_root = \"Rock-Paper-Scissors-merged\"\n",
    "\n",
    "classes = [\"rock\", \"paper\", \"scissors\"]\n",
    "splits = [\"train\", \"test\", \"validation\"]\n",
    "\n",
    "# 出力先フォルダ作成\n",
    "for cls in classes:\n",
    "    os.makedirs(os.path.join(dst_root, cls), exist_ok=True)\n",
    "\n",
    "# 各split内のクラスフォルダから画像をコピー\n",
    "for split in splits:\n",
    "    split_path = os.path.join(src_root, split)\n",
    "    if not os.path.isdir(split_path):\n",
    "        continue\n",
    "    for cls in classes:\n",
    "        cls_path = os.path.join(split_path, cls)\n",
    "        if not os.path.isdir(cls_path):\n",
    "            continue\n",
    "        for fname in os.listdir(cls_path):\n",
    "            src_file = os.path.join(cls_path, fname)\n",
    "            # ファイル名の重複を避けるためにsplit名をプレフィックスに追加\n",
    "            dst_file = os.path.join(dst_root, cls, f\"{split}_{fname}\")\n",
    "            shutil.copy2(src_file, dst_file)\n",
    "\n",
    "print(\"完了: Rock-Paper-Scissors-merged に統合しました\")\n",
    "for cls in classes:\n",
    "    count = len(os.listdir(os.path.join(dst_root, cls)))\n",
    "    print(f\"  {cls}: {count} 枚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3424e3d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     24\u001b[0m img_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 25\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mhands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n\u001b[0;32m     27\u001b[0m     lm \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlandmark\n",
      "File \u001b[1;32mc:\\Users\\Owner\\ProgramProject\\RockPaperScissors\\.venv\\lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    133\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\ProgramProject\\RockPaperScissors\\.venv\\lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "label_map = {\"rock\": 0, \"paper\": 1, \"scissors\": 2}\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5\n",
    ") as hands:\n",
    "    for label_name, label_id in label_map.items():\n",
    "        folder = os.path.join(dst_root, label_name)\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "        for fname in os.listdir(folder):\n",
    "            path = os.path.join(folder, fname)\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(img_rgb)\n",
    "            if results.multi_hand_landmarks:\n",
    "                lm = results.multi_hand_landmarks[0].landmark\n",
    "                arr = np.array([[p.x, p.y, p.z] for p in lm])  # shape (21, 3)\n",
    "                arr = arr.T  # shape (3, 21)\n",
    "                data_X.append(arr)\n",
    "                data_y.append(label_id)\n",
    "\n",
    "# numpy配列に変換\n",
    "X = np.stack(data_X)  # shape (N, 3, 21)\n",
    "y = np.array(data_y)  # shape (N,)\n",
    "\n",
    "# 保存\n",
    "np.savez_compressed(\"rps_hands_3x21.npz\", X=X, y=y)\n",
    "\n",
    "print(f\"データセット作成完了: {X.shape[0]} サンプル\")\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "for label_name, label_id in label_map.items():\n",
    "    print(f\"  {label_name}: {np.sum(y == label_id)} サンプル\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42fa3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\ProgramProject\\RockPaperScissors\\.venv\\Scripts\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cce5535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN 精度: 1.0000\n",
      "不正な手判定の距離閾値: 2.7722\n",
      "訓練データ距離の統計: mean=0.7764, std=0.5607\n",
      "\n",
      "分類器の準備完了\n",
      "ラベルマップ: {0: 'rock', 1: 'paper', 2: 'scissors', 3: 'invalid'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# データの準備（flattenして63次元に）\n",
    "data = np.load(\"rps_hands_3x21.npz\")\n",
    "X = data[\"X\"]  # shape (N, 3, 21)\n",
    "y = data[\"y\"]  # shape (N,)\n",
    "\n",
    "X_flat = X.reshape(X.shape[0], -1)  # shape (N, 63)\n",
    "\n",
    "# 訓練・テスト分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_flat, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 標準化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# k-NNモデルの学習\n",
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=k, metric=\"euclidean\")\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# テストデータで精度確認\n",
    "accuracy = knn.score(X_test_scaled, y_test)\n",
    "print(f\"k-NN 精度: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# 不正な手の検出用：k近傍への平均距離を計算\n",
    "def predict_with_rejection(model, scaler, X_new, threshold):\n",
    "    \"\"\"\n",
    "    予測と同時に、距離が閾値を超えたら「不正な手(ラベル3)」として返す\n",
    "    \"\"\"\n",
    "    X_scaled = scaler.transform(X_new.reshape(1, -1) if X_new.ndim == 1 else X_new)\n",
    "    distances, indices = model.kneighbors(X_scaled)\n",
    "    mean_distances = distances.mean(axis=1)\n",
    "\n",
    "    predictions = model.predict(X_scaled)\n",
    "    # 閾値を超えた場合は不正な手（ラベル3）\n",
    "    predictions = np.where(mean_distances > threshold, 3, predictions)\n",
    "\n",
    "    return predictions, mean_distances\n",
    "\n",
    "\n",
    "# 訓練データでの距離分布から閾値を決定\n",
    "train_distances, _ = knn.kneighbors(X_train_scaled)\n",
    "train_mean_distances = train_distances.mean(axis=1)\n",
    "\n",
    "# 閾値：訓練データの距離の95パーセンタイル + マージン\n",
    "threshold = np.percentile(train_mean_distances, 95) * 1.5\n",
    "print(f\"不正な手判定の距離閾値: {threshold:.4f}\")\n",
    "print(\n",
    "    f\"訓練データ距離の統計: mean={train_mean_distances.mean():.4f}, std={train_mean_distances.std():.4f}\"\n",
    ")\n",
    "\n",
    "# モデルと閾値を保存用に辞書化\n",
    "rps_classifier = {\n",
    "    \"model\": knn,\n",
    "    \"scaler\": scaler,\n",
    "    \"threshold\": threshold,\n",
    "    \"label_map\": {0: \"rock\", 1: \"paper\", 2: \"scissors\", 3: \"invalid\"},\n",
    "}\n",
    "\n",
    "print(\"\\n分類器の準備完了\")\n",
    "print(f\"ラベルマップ: {rps_classifier['label_map']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0047a3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分類器を 'rps_classifier.pkl' に保存しました\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# モデル、スケーラー、閾値、ラベルマップをまとめて保存\n",
    "joblib.dump(rps_classifier, \"rps_classifier.pkl\")\n",
    "\n",
    "print(\"分類器を 'rps_classifier.pkl' に保存しました\")\n",
    "\n",
    "# 読み込み確認（再起動後はこのコードで復元可能）\n",
    "# loaded_classifier = joblib.load(\"rps_classifier.pkl\")\n",
    "# knn = loaded_classifier[\"model\"]\n",
    "# scaler = loaded_classifier[\"scaler\"]\n",
    "# threshold = loaded_classifier[\"threshold\"]\n",
    "# label_map = loaded_classifier[\"label_map\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f98c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 分類器の取得\n",
    "model = rps_classifier[\"model\"]\n",
    "scaler_rps = rps_classifier[\"scaler\"]\n",
    "threshold_rps = rps_classifier[\"threshold\"]\n",
    "label_map_rps = rps_classifier[\"label_map\"]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    ") as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        label_text = \"No hand detected\"\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # ランドマーク描画\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, hand_landmarks, mp_hands.HAND_CONNECTIONS\n",
    "                )\n",
    "\n",
    "                # 21点の座標を取得\n",
    "                lm = hand_landmarks.landmark\n",
    "                arr = np.array([[p.x, p.y, p.z] for p in lm])  # shape (21, 3)\n",
    "                arr = arr.T  # shape (3, 21)\n",
    "                X_new = arr.flatten()  # shape (63,)\n",
    "\n",
    "                # スケーリングして予測\n",
    "                X_scaled = scaler_rps.transform(X_new.reshape(1, -1))\n",
    "                distances, _ = model.kneighbors(X_scaled)\n",
    "                mean_distance = distances.mean()\n",
    "\n",
    "                if mean_distance > threshold_rps:\n",
    "                    pred_label = 3  # invalid\n",
    "                else:\n",
    "                    pred_label = model.predict(X_scaled)[0]\n",
    "\n",
    "                label_text = f\"{label_map_rps[pred_label]} (dist: {mean_distance:.2f})\"\n",
    "\n",
    "        # 結果を表示\n",
    "        cv2.putText(\n",
    "            frame, label_text, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3\n",
    "        )\n",
    "        cv2.imshow(\"Rock Paper Scissors\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473cd2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a09b3",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rockpaperscissors (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
